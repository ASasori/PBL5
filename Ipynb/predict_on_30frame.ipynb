{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_train_8.classes import  load_model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "def mediapipe_detection(image, model):\n",
    "    # từ image, model dự đoán trả về kết quả (định dạng mặc định) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = None\n",
    "def update_mpresult(res,results):\n",
    "    global last\n",
    "    c = 0\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            if(c==20 and p.y>1.1 and last): last.right_hand_landmarks = None\n",
    "            elif(c==19 and p.y>1.1 and last): last.left_hand_landmarks = None\n",
    "            c+=1\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            c+=1\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last!=None and last.left_hand_landmarks: results.left_hand_landmarks = copy.deepcopy(last.left_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last!=None and last.right_hand_landmarks: results.right_hand_landmarks = copy.deepcopy(last.right_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    return results\n",
    "\n",
    "def normalize_keypoint(res,img=None):\n",
    "    #normalize keypoint\n",
    "    x1,y1,x2,y2 = res[11][0]*width,res[11][1]*height,res[12][0]*width,res[12][1]*height\n",
    "    try:\n",
    "        cv2.circle(img,(int(x1),int(y1)),4,(0,255,255),-1)\n",
    "        cv2.circle(img,(int(x2),int(y2)),4,(0,255,255),-1)\n",
    "    except:\n",
    "        # print(\"No img found\")\n",
    "        pass\n",
    "    dis = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    x_cen = (res[11][0]+res[12][0])/2\n",
    "    y_cen = (res[11][1]+res[12][1])/2\n",
    "    vector = [0.5-x_cen,0.5-y_cen]\n",
    "    scale = (200*width/640)/dis\n",
    "    for i in range(len(res)):\n",
    "        if res[i][0]==0 and res[i][1]==0:\n",
    "            continue\n",
    "        res[i][0] = vector[0]+res[i][0]\n",
    "        res[i][1] = vector[1]+res[i][1]\n",
    "        res[i][0] = 0.5+(res[i][0]-0.5)*scale\n",
    "        res[i][1] = 0.5+(res[i][1]-0.5)*scale\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract_keypoint(results):\n",
    "    global last\n",
    "    res = []\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z,p.visibility]))\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            res.append(np.array([0,0,0,0]))\n",
    "    #--------------\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!= None and last.left_hand_landmarks:\n",
    "        for p in last.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    #---------------\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!=None and last.right_hand_landmarks:\n",
    "        for p in last.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    return res\n",
    "\n",
    "def extract_keypoints_flatten(result,img = None):\n",
    "    #đây là hàm chính thức\n",
    "    res = extract_keypoint(result)\n",
    "    res = normalize_keypoint(res,img)\n",
    "    update_mpresult(res,result)\n",
    "    return np.concatenate([x for x in res])\n",
    "\n",
    "def numpy_to_filecsv(data,filename):\n",
    "    with open(filename,\"w\",newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile,delimiter=\",\")\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "def filecsv_to_numpy(filename,data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-05-21-13-07\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def get_time():\n",
    "    return datetime.now().strftime(\"%d-%m-%H-%M-%S\")\n",
    "print(get_time())\n",
    "Data_path = os.path.join(\"./PredictAndCollect\")\n",
    "if not os.path.exists(Data_path):\n",
    "    os.makedirs(Data_path)\n",
    "CSV_path = os.path.join(Data_path,\"CSV\")\n",
    "if not os.path.exists(CSV_path): os.makedirs(CSV_path)\n",
    "Video_path = os.path.join(Data_path,\"Video\") \n",
    "if not os.path.exists(Video_path): os.makedirs(Video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'ban', 'ban dem', 'ban ngay', 'bo', 'cam on', 'choi', 'cuoi', 'di', 'di hoc', 'khoc', 'lam viec', 'me', 'moi ngay', 'sach', 'toi', 'viet', 'xem', 'xin chao', 'xin loi']\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "num_frame = 30\n",
    "with open(\"label_list.json\") as js:\n",
    "    actions = list(json.load(js).values())\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "delay = 0\n",
    "frame_list = []\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #append frame to list\n",
    "        frame_list.append(frame)\n",
    "        #get keypoint \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        keypoints = extract_keypoints_flatten(results,image)\n",
    "        last = copy.deepcopy(results)\n",
    "        draw_landmarks(image=image,results=results)\n",
    "        sequence.append(keypoints)\n",
    "        image = cv2.flip(image,1)\n",
    "        #predict when get enough 30 frames\n",
    "        if (len(sequence)==30):\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            #res as category\n",
    "            #get label\n",
    "            label = actions[np.argmax(res)]\n",
    "            #save as video\n",
    "            vd_file_path = os.path.join(Video_path,label+\"_\"+get_time()+\".mp4\")\n",
    "            video_res = cv2.VideoWriter(vd_file_path,  \n",
    "                         cv2.VideoWriter_fourcc(*'MP4V'), \n",
    "                         10.0, (width,height)) \n",
    "            for fr in frame_list:\n",
    "                video_res.write(fr)\n",
    "            video_res.release()\n",
    "            frame_list = []\n",
    "            #save as csv\n",
    "            csv_file_path = os.path.join(CSV_path,label+\"_\"+get_time()+\".csv\")\n",
    "            numpy_to_filecsv(np.array(sequence),csv_file_path)\n",
    "            cv2.putText(image, f'Predicted: {label}', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(image, f'Save video in {vd_file_path},{csv_file_path}', (30,30), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            if cv2.waitKey(2000) & 0xFF == ord('q'):\n",
    "                break\n",
    "            sequence = []\n",
    "            continue\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
