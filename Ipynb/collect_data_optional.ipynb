{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import copy\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "width = 640\n",
    "height = 480\n",
    "# kích thước của open Cv vốn mặc định rồi\n",
    "# cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    # từ image, model dự đoán trả về kết quả (định dạng mặc định) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = None\n",
    "def update_mpresult(res,results):\n",
    "    c = 0\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            c+=1\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.left_hand_landmarks: results.left_hand_landmarks = copy.deepcopy(last.left_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.right_hand_landmarks: results.right_hand_landmarks = copy.deepcopy(last.right_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    return results\n",
    "\n",
    "def normalize_keypoint(res,img=None):\n",
    "    #normalize keypoint\n",
    "    x1,y1,x2,y2 = res[11][0]*width,res[11][1]*height,res[12][0]*width,res[12][1]*height\n",
    "    try:\n",
    "        cv2.circle(img,(int(x1),int(y1)),4,(0,255,255),-1)\n",
    "        cv2.circle(img,(int(x2),int(y2)),4,(0,255,255),-1)\n",
    "    except:\n",
    "        # print(\"No img found\")\n",
    "        pass\n",
    "    dis = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    x_cen = (res[11][0]+res[12][0])/2\n",
    "    y_cen = (res[11][1]+res[12][1])/2\n",
    "    vector = [0.5-x_cen,0.5-y_cen]\n",
    "    scale = (200*width/640)/dis\n",
    "    for i in range(len(res)):\n",
    "        if res[i][0]==0 and res[i][1]==0:\n",
    "            continue\n",
    "        res[i][0] = vector[0]+res[i][0]\n",
    "        res[i][1] = vector[1]+res[i][1]\n",
    "        res[i][0] = 0.5+(res[i][0]-0.5)*scale\n",
    "        res[i][1] = 0.5+(res[i][1]-0.5)*scale\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract_keypoint(results):\n",
    "    global last\n",
    "    res = []\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z,p.visibility]))\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            res.append(np.array([0,0,0,0]))\n",
    "    #--------------\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!= None and last.left_hand_landmarks:\n",
    "        for p in last.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    #---------------\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!=None and last.right_hand_landmarks:\n",
    "        for p in last.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    return res\n",
    "\n",
    "def extract_keypoints_flatten(result,img = None):\n",
    "    #đây là hàm chính thức\n",
    "    res = extract_keypoint(result)\n",
    "    res = normalize_keypoint(res,img)\n",
    "    update_mpresult(res,result)\n",
    "    return np.concatenate([x for x in res])\n",
    "\n",
    "def numpy_to_filecsv(data,filename):\n",
    "    with open(filename,\"w\",newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile,delimiter=\",\")\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "def filecsv_to_numpy(filename,data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing mediapipe in a frame\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     ret, frame = cap.read()\n",
    "#     print(ret)\n",
    "#     frame,result = mediapipe_detection(frame,holistic)\n",
    "#     res = extract_keypoints_flatten(result)\n",
    "#     draw_landmarks(frame,result)\n",
    "#     frame = cv2.flip(frame,1)\n",
    "#     cap.release()\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(img)\n",
    "#     print(res.shape)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mặc kệ đoạn code ở trên, bắt đầu thu từ đây\n",
    "\n",
    "- Điều chỉnh lựa chọn folder thu:\n",
    "    - Lỗi lỏ của python nên điền số tạm nhé\n",
    "    - Chạy 2 cell bên dưới để biết nên điền số nào\n",
    "- Khi cửa sổ hiện lên, bắt đầu thu theo quy tắc là:\n",
    "    - Chữ starting collect sẽ đơ trong 1.5s, vào tư thế chuẩn bị thu\n",
    "    - Quá trình thu diễn ra trong 30 frame, điều chỉnh một động tác sao cho nó khớp đúng 30 frame\n",
    "    - Nhấn q để huỷ quá trình thu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"group_tu.txt\",\"r\",encoding='utf-8') as ip:\n",
    "    all_actions = [x.split(\"\\n\")[0].strip() for x in ip.readlines()]\n",
    "all_actions = np.array(all_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Ban ngày   1. Ban đêm   2. Bố   3. Cười   4. Cảm ơn   \n",
      "5. Khóc   6. Mẹ   7. Sách   8. Xin chào   9. Ăn   \n",
      "10. Viết   11. Xem   12. Xin lỗi   13. Đi học   14. Đi   \n",
      "15. Chơi   16. Tôi   17. Bạn   18. Mỗi ngày   19. Làm việc   \n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for i,j in enumerate(all_actions):\n",
    "    s += f\"{i}. {j}   \"\n",
    "    if i%5==4:\n",
    "        print(s)\n",
    "        s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collected_actions(x,y):\n",
    "    #hàm để chọn tiện ra một số label để thu, để khi dừng đang thu giữa chừng thu lại cho tiện\n",
    "    #quay từ label X đến hết label Y\n",
    "    get = False\n",
    "    res = []\n",
    "    for i,name in enumerate(all_actions):\n",
    "        if (i==x):\n",
    "            get = True\n",
    "        if get:\n",
    "            res.append(name)\n",
    "        if (i==y):\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting... in 2s\n",
      "['Đi học']\n",
      "qCollecting frames for Đi học Video Number 60\n",
      "qCollecting frames for Đi học Video Number 61\n",
      "qCollecting frames for Đi học Video Number 62\n",
      "qCollecting frames for Đi học Video Number 63\n",
      "qCollecting frames for Đi học Video Number 64\n",
      "qCollecting frames for Đi học Video Number 65\n",
      "qCollecting frames for Đi học Video Number 66\n",
      "qCollecting frames for Đi học Video Number 67\n",
      "qCollecting frames for Đi học Video Number 68\n",
      "qCollecting frames for Đi học Video Number 69\n",
      "qCollecting frames for Đi học Video Number 70\n",
      "qCollecting frames for Đi học Video Number 71\n",
      "qCollecting frames for Đi học Video Number 72\n",
      "qCollecting frames for Đi học Video Number 73\n",
      "qCollecting frames for Đi học Video Number 74\n",
      "qCollecting frames for Đi học Video Number 75\n",
      "qCollecting frames for Đi học Video Number 76\n",
      "qCollecting frames for Đi học Video Number 77\n",
      "qCollecting frames for Đi học Video Number 78\n",
      "qCollecting frames for Đi học Video Number 79\n",
      "qCollecting frames for Đi học Video Number 80\n",
      "qCollecting frames for Đi học Video Number 81\n",
      "qCollecting frames for Đi học Video Number 82\n",
      "qCollecting frames for Đi học Video Number 83\n",
      "qCollecting frames for Đi học Video Number 84\n",
      "qCollecting frames for Đi học Video Number 85\n",
      "qCollecting frames for Đi học Video Number 86\n",
      "qCollecting frames for Đi học Video Number 87\n",
      "qCollecting frames for Đi học Video Number 88\n",
      "qCollecting frames for Đi học Video Number 89\n",
      "qCollecting frames for Đi học Video Number 90\n",
      "qCollecting frames for Đi học Video Number 91\n",
      "qCollecting frames for Đi học Video Number 92\n",
      "qCollecting frames for Đi học Video Number 93\n",
      "qCollecting frames for Đi học Video Number 94\n",
      "qCollecting frames for Đi học Video Number 95\n",
      "qCollecting frames for Đi học Video Number 96\n",
      "qCollecting frames for Đi học Video Number 97\n",
      "qCollecting frames for Đi học Video Number 98\n",
      "qCollecting frames for Đi học Video Number 99\n",
      "qCollecting frames for Đi học Video Number 100\n",
      "qCollecting frames for Đi học Video Number 101\n",
      "qCollecting frames for Đi học Video Number 102\n",
      "qCollecting frames for Đi học Video Number 103\n",
      "qCollecting frames for Đi học Video Number 104\n",
      "qCollecting frames for Đi học Video Number 105\n",
      "qCollecting frames for Đi học Video Number 106\n",
      "qCollecting frames for Đi học Video Number 107\n",
      "qCollecting frames for Đi học Video Number 108\n",
      "qCollecting frames for Đi học Video Number 109\n",
      "qCollecting frames for Đi học Video Number 110\n",
      "qCollecting frames for Đi học Video Number 111\n",
      "qCollecting frames for Đi học Video Number 112\n",
      "qCollecting frames for Đi học Video Number 113\n",
      "qCollecting frames for Đi học Video Number 114\n",
      "qCollecting frames for Đi học Video Number 115\n",
      "qCollecting frames for Đi học Video Number 116\n",
      "qCollecting frames for Đi học Video Number 117\n",
      "qCollecting frames for Đi học Video Number 118\n",
      "qCollecting frames for Đi học Video Number 119\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join('Pending upload\\\\AnhNguyen_data') \n",
    "Video_Data_Path = os.path.join('Pending upload\\\\AnhNguyen_data_video')\n",
    "start_vid_num = 120 #Chỉ số video bắt đầu\n",
    "no_sequences = 20 #số video cho một nhãn\n",
    "sequence_length = 30 # số frame cho một video\n",
    "delay_ms = 2000 # khoảng thời gian tương đối giữa hai vid liên tiếp\n",
    "\n",
    "with open(\"group_tu2.txt\",\"r\",encoding='utf-8') as ip:\n",
    "    all_actions = [x.split(\"\\n\")[0].strip() for x in ip.readlines()]\n",
    "all_actions = np.array(all_actions)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.3, min_tracking_confidence=0.3) as holistic:\n",
    "    print(\"starting... in 2s\")\n",
    "    cv2.waitKey(2000)\n",
    "    stop = False\n",
    "    actions = collected_actions(0,0) \n",
    "    print(actions)\n",
    "    for action in actions:\n",
    "        if stop: break\n",
    "        folder_path = os.path.join(DATA_PATH,action)\n",
    "        vid_path = os.path.join(Video_Data_Path,action)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        if not os.path.exists(vid_path):\n",
    "            os.makedirs(vid_path)\n",
    "        for sequence in range(no_sequences):\n",
    "            sequence+=start_vid_num\n",
    "            if stop: break\n",
    "            #lặp trên từng mẫu, từng video\n",
    "            #với mỗi sequence, output ra 1 file csv tại data/action/sequence\n",
    "            file_path = os.path.join(folder_path,str(sequence)+\".csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                continue\n",
    "            video_res = cv2.VideoWriter(os.path.join(vid_path,str(sequence)+\".mp4\"),  \n",
    "                         cv2.VideoWriter_fourcc(*'MP4V'), \n",
    "                         10.0, (width,height)) \n",
    "            seq_list = []\n",
    "            for frame_num in range(sequence_length+1):\n",
    "                ret, frame = cap.read()\n",
    "                if frame_num == 0:\n",
    "                    frame = cv2.flip(frame,1) \n",
    "                    cv2.putText(frame, f'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, f'{action} video Number {sequence}', (30,30), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    print('qCollecting frames for {} Video Number {}'.format(action, sequence))\n",
    "                    cv2.imshow('OpenCV Feed', frame)\n",
    "                    if cv2.waitKey(delay_ms) & 0xFF == ord('q'):\n",
    "                        stop = True\n",
    "                        video_res.release()\n",
    "                        break\n",
    "                    continue\n",
    "                video_res.write(frame)\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                res = extract_keypoints_flatten(results)\n",
    "                draw_landmarks(image, results)\n",
    "                image = cv2.flip(image,1)\n",
    "                if frame_num!=0:\n",
    "                    cv2.putText(image, f'{action} video Number {sequence}', \n",
    "                                (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                seq_list.append(res)\n",
    "                last = copy.deepcopy(results)\n",
    "                if frame_num== sequence_length and stop == False:\n",
    "                    numpy_to_filecsv(np.array(seq_list),file_path)\n",
    "                    seq_list = []\n",
    "\n",
    "                # Nhấn giữ Q để dừng, nhớ xoá video cuối cùng.\n",
    "                if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "                    stop = True\n",
    "                    video_res.release() \n",
    "                    break\n",
    "            last = None\n",
    "            video_res.release()   \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
