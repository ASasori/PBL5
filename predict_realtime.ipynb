{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECA(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
    "        nn = tf.expand_dims(nn, -1)\n",
    "        nn = self.conv(nn)\n",
    "        nn = tf.squeeze(nn, -1)\n",
    "        nn = tf.nn.sigmoid(nn)\n",
    "        nn = nn[:,None,:]\n",
    "        return inputs * nn\n",
    "\n",
    "class LateDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.rate = rate\n",
    "        self.start_step = start_step\n",
    "        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n",
    "      \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
    "        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n",
    "        if training:\n",
    "            self._train_counter.assign_add(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalDWConv1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        name='', **kwargs):\n",
    "        super().__init__(name=name,**kwargs)\n",
    "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
    "                            kernel_size,\n",
    "                            strides=1,\n",
    "                            dilation_rate=dilation_rate,\n",
    "                            padding='valid',\n",
    "                            use_bias=use_bias,\n",
    "                            depthwise_initializer=depthwise_initializer,\n",
    "                            name=name + '_dwconv')\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.causal_pad(inputs)\n",
    "        x = self.dw_conv(x)\n",
    "        return x\n",
    "\n",
    "def Conv1DBlock(channel_size,\n",
    "          kernel_size,\n",
    "          dilation_rate=1,\n",
    "          drop_rate=0.0,\n",
    "          expand_ratio=2,\n",
    "          se_ratio=0.25,\n",
    "          activation='swish',\n",
    "          name=None):\n",
    "    '''\n",
    "    efficient conv1d block, @hoyso48\n",
    "    '''\n",
    "    if name is None:\n",
    "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
    "    # Expansion phase\n",
    "    def apply(inputs):\n",
    "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
    "        channels_expand = channels_in * expand_ratio\n",
    "\n",
    "        skip = inputs\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channels_expand,\n",
    "            use_bias=True,\n",
    "            activation=activation,\n",
    "            name=name + '_expand_conv')(inputs)\n",
    "\n",
    "        # Depthwise Convolution\n",
    "        x = CausalDWConv1D(kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            use_bias=False,\n",
    "            name=name + '_dwconv')(x)\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
    "\n",
    "        x  = ECA()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channel_size,\n",
    "            use_bias=True,\n",
    "            name=name + '_project_conv')(x)\n",
    "\n",
    "        if drop_rate > 0:\n",
    "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
    "\n",
    "        if (channels_in == channel_size):\n",
    "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.scale = self.dim ** -0.5\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
    "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        qkv = self.qkv(inputs)\n",
    "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
    "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
    "\n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask[:, None, None, :]\n",
    "\n",
    "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
    "        attn = self.drop1(attn)\n",
    "\n",
    "        x = attn @ v\n",
    "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply\n",
    "MAX_LEN = 30\n",
    "CHANNELS = 258\n",
    "NUM_CLASSES = 20\n",
    "\n",
    "# ----------------------------------------- DEFINE MODEL -----------------------------\n",
    "def get_model(max_len=MAX_LEN, dropout_step=0, dim=192):\n",
    "    inp = tf.keras.Input((max_len,CHANNELS))\n",
    "    x = inp\n",
    "    ksize = 3\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.3)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.3)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(dim*2,activation=None,name='top_conv')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    # x = LateDropout(0.2, start_step=dropout_step)(x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES,name='classifier',activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  load_model\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1DCNN_transformer.tf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:239\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:145\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    142\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load ShardedVariables\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[1;32m--> 145\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m keras_loader\u001b[38;5;241m.\u001b[39mfinalize_objects()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:1043\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m   1042\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1045\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:161\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:456\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# import).\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 456\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_def_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_input_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_input_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n\u001b[0;32m    462\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:97\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001b[0m\n\u001b[0;32m     91\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     92\u001b[0m     fdef, input_shapes, include_library_functions\u001b[38;5;241m=\u001b[39minclude_library_functions\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     96\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m   \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_graph_def_for_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_device_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpropagate_device_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m   \u001b[38;5;66;03m# Initialize fields specific to FuncGraph.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[0;32m    102\u001b[0m   \u001b[38;5;66;03m# inputs\u001b[39;00m\n\u001b[0;32m    103\u001b[0m   input_tensor_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    104\u001b[0m       nested_to_flat_tensor_name[arg\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m fdef\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39minput_arg\n\u001b[0;32m    105\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\importer.py:418\u001b[0m, in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name, propagate_device_spec)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph_def_for_function\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, propagate_device_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_graph_def_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_colocation_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpropagate_device_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpropagate_device_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\importer.py:510\u001b[0m, in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list, propagate_device_spec)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer(graph_def\u001b[38;5;241m.\u001b[39mSerializeToString()) \u001b[38;5;28;01mas\u001b[39;00m serialized:\n\u001b[0;32m    509\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    511\u001b[0m \u001b[43m      \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphImportGraphDefWithResults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m          \u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     results \u001b[38;5;241m=\u001b[39m c_api_util\u001b[38;5;241m.\u001b[39mScopedTFImportGraphDefResults(results)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2073\u001b[0m, in \u001b[0;36mGraph.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2071\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2073\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   2074\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import  load_model\n",
    "model = load_model('1DCNN_transformer.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16) for _ in range(20)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "def mediapipe_detection(image, model):\n",
    "    # từ image, model dự đoán trả về kết quả (định dạng mặc định) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = None\n",
    "def update_mpresult(res,results):\n",
    "    c = 0\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            c+=1\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.left_hand_landmarks: results.left_hand_landmarks = copy.deepcopy(last.left_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.right_hand_landmarks: results.right_hand_landmarks = copy.deepcopy(last.right_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    return results\n",
    "\n",
    "def normalize_keypoint(res,img=None):\n",
    "    #normalize keypoint\n",
    "    x1,y1,x2,y2 = res[11][0]*width,res[11][1]*height,res[12][0]*width,res[12][1]*height\n",
    "    try:\n",
    "        cv2.circle(img,(int(x1),int(y1)),4,(0,255,255),-1)\n",
    "        cv2.circle(img,(int(x2),int(y2)),4,(0,255,255),-1)\n",
    "    except:\n",
    "        # print(\"No img found\")\n",
    "        pass\n",
    "    dis = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    x_cen = (res[11][0]+res[12][0])/2\n",
    "    y_cen = (res[11][1]+res[12][1])/2\n",
    "    vector = [0.5-x_cen,0.5-y_cen]\n",
    "    scale = (200*width/640)/dis\n",
    "    for i in range(len(res)):\n",
    "        if res[i][0]==0 and res[i][1]==0:\n",
    "            continue\n",
    "        res[i][0] = vector[0]+res[i][0]\n",
    "        res[i][1] = vector[1]+res[i][1]\n",
    "        res[i][0] = 0.5+(res[i][0]-0.5)*scale\n",
    "        res[i][1] = 0.5+(res[i][1]-0.5)*scale\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract_keypoint(results):\n",
    "    global last\n",
    "    res = []\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z,p.visibility]))\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            res.append(np.array([0,0,0,0]))\n",
    "    #--------------\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!= None and last.left_hand_landmarks:\n",
    "        for p in last.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    #---------------\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!=None and last.right_hand_landmarks:\n",
    "        for p in last.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    return res\n",
    "\n",
    "def extract_keypoints_flatten(result,img = None):\n",
    "    #đây là hàm chính thức\n",
    "    res = extract_keypoint(result)\n",
    "    res = normalize_keypoint(res,img)\n",
    "    update_mpresult(res,result)\n",
    "    return np.concatenate([x for x in res])\n",
    "\n",
    "def numpy_to_filecsv(data,filename):\n",
    "    with open(filename,\"w\",newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile,delimiter=\",\")\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "def filecsv_to_numpy(filename,data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "xin loi\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "xin loi\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "toi\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "di\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "ban dem\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "ban\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "moi ngay\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "ban\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "num_frame = 30\n",
    "Data_path = os.path.join('./data_split/Train')\n",
    "actions = np.array(os.listdir(Data_path))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "delay = 0\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        keypoints = extract_keypoints_flatten(results,image)\n",
    "        draw_landmarks(image=image,results=results)\n",
    "        # last =  copy.deepcopy(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        image = cv2.flip(image,1)\n",
    "        if delay !=0:\n",
    "            delay -=1\n",
    "        elif delay == 0 and len(sequence)%10 == 0 and len(sequence)>=num_frame:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                            delay = 30\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                        delay = 30\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
