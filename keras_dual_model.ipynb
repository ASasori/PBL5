{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv3D, BatchNormalization, Flatten, Dropout, MaxPooling3D, LSTM, Dense, ZeroPadding3D\n",
    "from keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "num_frames = 20 # changing requires model refactoring\n",
    "\n",
    "def load_video(directory):\n",
    "    cap = cv2.VideoCapture(directory)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    return np.array(frames)/255\n",
    "\n",
    "def load_txt(directory):\n",
    "    df = pd.read_csv(directory)\n",
    "    dataset = df.iloc[1:,1:]\n",
    "    return np.array(dataset)\n",
    "\n",
    "def load_data(directory):\n",
    "    label_count = 0\n",
    "    X_fr_train = []\n",
    "    X_mk_train = []\n",
    "    y_train = []\n",
    "\n",
    "    X_fr_test =  []\n",
    "    X_mk_test = []\n",
    "    y_test = []\n",
    "\n",
    "    list_label = os.listdir(directory)\n",
    "    for label in list_label:\n",
    "        count = 0\n",
    "        subpath = os.path.join(directory,label)\n",
    "        files = os.listdir(subpath)\n",
    "\n",
    "        files_txt = [txt for txt in files if txt.endswith(\".txt\")]\n",
    "        files_mp4 = [mp4 for mp4 in files if mp4.endswith(\".mp4\")]\n",
    "\n",
    "        if len(files_txt)!=len(files_mp4):\n",
    "            raise RuntimeError(\"The amount of .txt and .mp4 files are not equal. Found {} .mp4 but {} .txt\".format(len(files_mp4),len(files_txt)))\n",
    "        \n",
    "        n = len(files_txt)\n",
    "        \n",
    "        for i in range(n):\n",
    "            frames = load_video(os.path.join(subpath,files_mp4[i]))\n",
    "            marks = load_txt(os.path.join(subpath,files_txt[i]))\n",
    "            n_samples = marks.shape[0]\n",
    "            if count>=1000:\n",
    "                break\n",
    "            for j in range(num_frames, n_samples, 5):\n",
    "                count+=1\n",
    "                if count%4!=0:\n",
    "                    X_fr_train.append(frames[j-num_frames:j,::])\n",
    "                    X_mk_train.append(marks[j-num_frames:j,:])\n",
    "                    y_train.append(label_count)    \n",
    "                    continue\n",
    "                X_fr_test.append(frames[j-num_frames:j,::])\n",
    "                X_mk_test.append(marks[j-num_frames:j,:])\n",
    "                y_test.append(label_count)\n",
    "        label_count+=1\n",
    "    return X_fr_train,X_mk_train, y_train, X_fr_test, X_mk_test, y_test, list_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM():\n",
    "    return Sequential([\n",
    "        LSTM(126,return_sequences=True,kernel_regularizer=L2()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.2),\n",
    "        \n",
    "        LSTM(63,return_sequences=True,kernel_regularizer=L2()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.2),\n",
    "\n",
    "        Flatten()\n",
    "    ])\n",
    "\n",
    "def create_Conv3D(): # designed for 20 128 128 3\n",
    "    return Sequential([\n",
    "        Conv3D(16,\n",
    "                kernel_size=(3,3,3),\n",
    "                strides=(1,1,1),\n",
    "                padding=\"same\",\n",
    "                data_format=\"channels_last\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2()),\n",
    "        MaxPooling3D(pool_size=(2,2,2),\n",
    "                strides=(1,2,2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv3D(32,\n",
    "                kernel_size=(3,3,3),\n",
    "                strides=(1,1,1),\n",
    "                padding=\"same\",\n",
    "                data_format=\"channels_last\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2()),\n",
    "        MaxPooling3D(pool_size=(2,2,2),\n",
    "                strides=(1,2,2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv3D(64,\n",
    "                kernel_size=(3,3,3),\n",
    "                strides=(1,1,1),\n",
    "                padding=\"same\",\n",
    "                data_format=\"channels_last\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2()),\n",
    "        MaxPooling3D(pool_size=(2,2,2),\n",
    "                strides=(2,2,2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv3D(128,\n",
    "                kernel_size=(3,3,3),\n",
    "                strides=(1,1,1),\n",
    "                padding=\"same\",\n",
    "                data_format=\"channels_last\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2()),\n",
    "        MaxPooling3D(pool_size=(2,2,2),\n",
    "                strides=(2,2,2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        ZeroPadding3D(((1,2),(0,0),(0,0)), data_format=\"channels_last\"),\n",
    "        MaxPooling3D(pool_size=(2,2,2),\n",
    "                strides=(2,2,2)),\n",
    "        Flatten()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# first build model\n",
    "\n",
    "class ConvLSTM(Model):\n",
    "    def __init__(self, out_classes):\n",
    "        super().__init__()\n",
    "        self.branch1 = create_Conv3D()\n",
    "        self.branch2 = create_LSTM()\n",
    "\n",
    "        self.classifier = Sequential([\n",
    "            Dense(out_classes,activation=\"softmax\")\n",
    "        ])\n",
    "\n",
    "    def call(self, inp):\n",
    "        inp_frame = self.branch1(inp[0])\n",
    "        inp_mark = self.branch2(inp[1])\n",
    "        out = tf.concat((inp_frame,inp_mark),axis=1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Data_processed/\"\n",
    "X_fr_train, X_mk_train, y_train, X_fr_test, X_mk_test, y_test, list_label = load_data(directory)\n",
    "\n",
    "print(len(y_train),len(y_test))\n",
    "y_train, y_test = np.array(y_train) , np.array(y_test)\n",
    "X_fr_train = np.array(X_fr_train)\n",
    "X_fr_test = np.array(X_fr_test)\n",
    "X_mk_train = np.array(X_mk_train)\n",
    "X_mk_test = np.array(X_mk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# conv3d = create_Conv3D()\n",
    "input1 = np.random.randn(16,20,128,128,3)\n",
    "input2 = np.random.randn(16,20,126)\n",
    "model = ConvLSTM(28)\n",
    "output = model([input1,input2])\n",
    "print(output.shape)\n",
    "model.load_weights(\"testconv3dlstm_PBL5.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = np.random.randn(1,20,128,128,3)\n",
    "input2 = np.random.randn(1,20,126)\n",
    "output = model([input1,input2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Adamax\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=Adamax(),\n",
    "              metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(\n",
    "\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,filepath=\"testconv3dlstm_PBL5_functional_apis.keras\",\n",
    "    # save_weights_only=True,filepath=\"testconv3dlstm_PBL5_functional_apis.weights.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_fr_train,X_mk_train],y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=16,\n",
    "                    validation_data=([X_fr_test,X_mk_test],y_test),\n",
    "                    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"testconv3dlstm_PBL5.weights.h5\")\n",
    "model.evaluate([X_fr_train,X_mk_train],y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
