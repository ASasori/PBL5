{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import copy\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "width = 640\n",
    "height = 480\n",
    "# kích thước của open Cv vốn mặc định rồi\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    # từ image, model dự đoán trả về kết quả (định dạng mặc định) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = None\n",
    "def update_mpresult(res,results):\n",
    "    c = 0\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            c+=1\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.left_hand_landmarks: results.left_hand_landmarks = copy.deepcopy(last.left_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            p.x = res[c][0]\n",
    "            p.y = res[c][1]\n",
    "            c+=1\n",
    "    else:\n",
    "        if last and last.right_hand_landmarks: results.right_hand_landmarks = copy.deepcopy(last.right_hand_landmarks)\n",
    "        for _ in range(21):\n",
    "            c+=1\n",
    "    return results\n",
    "\n",
    "def normalize_keypoint(res,img=None):\n",
    "    #normalize keypoint\n",
    "    x1,y1,x2,y2 = res[11][0]*width,res[11][1]*height,res[12][0]*width,res[12][1]*height\n",
    "    try:\n",
    "        cv2.circle(img,(int(x1),int(y1)),4,(0,255,255),-1)\n",
    "        cv2.circle(img,(int(x2),int(y2)),4,(0,255,255),-1)\n",
    "    except:\n",
    "        # print(\"No img found\")\n",
    "        pass\n",
    "    dis = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    x_cen = (res[11][0]+res[12][0])/2\n",
    "    y_cen = (res[11][1]+res[12][1])/2\n",
    "    vector = [0.5-x_cen,0.5-y_cen]\n",
    "    scale = (200*width/640)/dis\n",
    "    for i in range(len(res)):\n",
    "        if res[i][0]==0 and res[i][1]==0:\n",
    "            continue\n",
    "        res[i][0] = vector[0]+res[i][0]\n",
    "        res[i][1] = vector[1]+res[i][1]\n",
    "        res[i][0] = 0.5+(res[i][0]-0.5)*scale\n",
    "        res[i][1] = 0.5+(res[i][1]-0.5)*scale\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract_keypoint(results):\n",
    "    global last\n",
    "    res = []\n",
    "    if results.pose_landmarks:\n",
    "        for p in results.pose_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z,p.visibility]))\n",
    "    else:\n",
    "        for _ in range(33):\n",
    "            res.append(np.array([0,0,0,0]))\n",
    "    #--------------\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!= None and last.left_hand_landmarks:\n",
    "        for p in last.left_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    #---------------\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    elif last!=None and last.right_hand_landmarks:\n",
    "        for p in last.right_hand_landmarks.landmark:\n",
    "            res.append(np.array([p.x,p.y,p.z]))\n",
    "    else:\n",
    "        for _ in range(21):\n",
    "            res.append(np.array([0,0,0]))\n",
    "    return res\n",
    "\n",
    "def extract_keypoints_flatten(result,img = None):\n",
    "    #đây là hàm chính thức\n",
    "    res = extract_keypoint(result)\n",
    "    res = normalize_keypoint(res,img)\n",
    "    update_mpresult(res,result)\n",
    "    return np.concatenate([x for x in res])\n",
    "\n",
    "def numpy_to_filecsv(data,filename):\n",
    "    with open(filename,\"w\",newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile,delimiter=\",\")\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "def filecsv_to_numpy(filename,data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing mediapipe in a frame\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     ret, frame = cap.read()\n",
    "#     print(ret)\n",
    "#     frame,result = mediapipe_detection(frame,holistic)\n",
    "#     res = extract_keypoints_flatten(result)\n",
    "#     draw_landmarks(frame,result)\n",
    "#     frame = cv2.flip(frame,1)\n",
    "#     cap.release()\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(img)\n",
    "#     print(res.shape)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mặc kệ đoạn code ở trên, bắt đầu thu từ đây\n",
    "\n",
    "- Điều chỉnh lựa chọn folder thu:\n",
    "    - Lỗi lỏ của python nên điền số tạm nhé\n",
    "    - Chạy 2 cell bên dưới để biết nên điền số nào\n",
    "- Khi cửa sổ hiện lên, bắt đầu thu theo quy tắc là:\n",
    "    - Chữ starting collect sẽ đơ trong 1.5s, vào tư thế chuẩn bị thu\n",
    "    - Quá trình thu diễn ra trong 30 frame, điều chỉnh một động tác sao cho nó khớp đúng 30 frame\n",
    "    - Nhấn q để huỷ quá trình thu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"group_tu.txt\",\"r\",encoding='utf-8') as ip:\n",
    "    all_actions = [x.split(\"\\n\")[0].strip() for x in ip.readlines()]\n",
    "all_actions = np.array(all_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Ban ngày   1. Ban đêm   2. Bố   3. Cười   4. Cảm ơn   \n",
      "5. Khóc   6. Cơm   7. Mẹ   8. Sách   9. Xin chào   \n",
      "10. Ăn   11. Viết   12. Xem   13. Xin lỗi   14. Đi học   \n",
      "15. Đi   16. Vẽ   17. Chơi   18. Tôi   19. Bạn   \n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for i,j in enumerate(all_actions):\n",
    "    s += f\"{i}. {j}   \"\n",
    "    if i%5==4:\n",
    "        print(s)\n",
    "        s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collected_actions(x,y):\n",
    "    #hàm để chọn tiện ra một số label để thu, để khi dừng đang thu giữa chừng thu lại cho tiện\n",
    "    #quay từ label X đến hết label Y\n",
    "    get = False\n",
    "    res = []\n",
    "    for i,name in enumerate(all_actions):\n",
    "        if (i==x):\n",
    "            get = True\n",
    "        if get:\n",
    "            res.append(name)\n",
    "        if (i==y):\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting... in 2s\n",
      "['Ăn']\n",
      "Collecting frames for Ăn Video Number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frames for Ăn Video Number 1\n",
      "Collecting frames for Ăn Video Number 2\n",
      "Collecting frames for Ăn Video Number 3\n",
      "Collecting frames for Ăn Video Number 4\n",
      "Collecting frames for Ăn Video Number 5\n",
      "Collecting frames for Ăn Video Number 6\n",
      "Collecting frames for Ăn Video Number 7\n",
      "Collecting frames for Ăn Video Number 8\n",
      "Collecting frames for Ăn Video Number 9\n",
      "Collecting frames for Ăn Video Number 10\n",
      "Collecting frames for Ăn Video Number 11\n",
      "Collecting frames for Ăn Video Number 12\n",
      "Collecting frames for Ăn Video Number 13\n",
      "Collecting frames for Ăn Video Number 14\n",
      "Collecting frames for Ăn Video Number 15\n",
      "Collecting frames for Ăn Video Number 16\n",
      "Collecting frames for Ăn Video Number 17\n",
      "Collecting frames for Ăn Video Number 18\n",
      "Collecting frames for Ăn Video Number 19\n",
      "Collecting frames for Ăn Video Number 60\n",
      "Collecting frames for Ăn Video Number 61\n",
      "Collecting frames for Ăn Video Number 62\n",
      "Collecting frames for Ăn Video Number 63\n",
      "Collecting frames for Ăn Video Number 64\n",
      "Collecting frames for Ăn Video Number 65\n",
      "Collecting frames for Ăn Video Number 66\n",
      "Collecting frames for Ăn Video Number 67\n",
      "Collecting frames for Ăn Video Number 68\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join('data') \n",
    "Video_Data_Path = os.path.join('data_video')\n",
    "with open(\"group_tu2.txt\",\"r\",encoding='utf-8') as ip:\n",
    "    all_actions = [x.split(\"\\n\")[0].strip() for x in ip.readlines()]\n",
    "all_actions = np.array(all_actions)\n",
    "start = 0 # bắt đầu thu từ Buổi chiều\n",
    "end = 0 # Thu hết buổi chiều thì dừng\n",
    "no_sequences = 60 #số video cho một nhãn\n",
    "sequence_length = 30 # số frame cho một video\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.3, min_tracking_confidence=0.3) as holistic:\n",
    "    print(\"starting... in 2s\")\n",
    "    cv2.waitKey(2000)\n",
    "    stop = False\n",
    "    actions = collected_actions(start,end) \n",
    "    print(actions)\n",
    "    for action in actions:\n",
    "        if stop: break\n",
    "        folder_path = os.path.join(DATA_PATH,action)\n",
    "        vid_path = os.path.join(Video_Data_Path,action)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        if not os.path.exists(vid_path):\n",
    "            os.makedirs(vid_path)\n",
    "        for sequence in range(no_sequences):\n",
    "            if stop: break\n",
    "            #lặp trên từng mẫu, từng video\n",
    "            #với mỗi sequence, output ra 1 file csv tại data/action/sequence\n",
    "            file_path = os.path.join(folder_path,str(sequence)+\".csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                continue\n",
    "            video_res = cv2.VideoWriter(os.path.join(vid_path,str(sequence)+\".mp4\"),  \n",
    "                         cv2.VideoWriter_fourcc(*'MP4V'), \n",
    "                         10.0, (width,height)) \n",
    "            seq_list = []\n",
    "            for frame_num in range(sequence_length+1):\n",
    "                ret, frame = cap.read()\n",
    "                if frame_num == 0:\n",
    "                    frame = cv2.flip(frame,1) \n",
    "                    cv2.putText(frame, f'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, f'{action} video Number {sequence}', (30,30), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    print('Collecting frames for {} Video Number {}'.format(action, sequence))\n",
    "                    cv2.imshow('OpenCV Feed', frame)\n",
    "                    if cv2.waitKey(750) & 0xFF == ord('q'):\n",
    "                        stop = True\n",
    "                        video_res.release()\n",
    "                        break\n",
    "                    continue\n",
    "                video_res.write(frame)\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                res = extract_keypoints_flatten(results)\n",
    "                draw_landmarks(image, results)\n",
    "                image = cv2.flip(image,1)\n",
    "                if frame_num!=0:\n",
    "                    cv2.putText(image, f'{action} video Number {sequence}', \n",
    "                                (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                seq_list.append(res)\n",
    "                last = copy.deepcopy(results)\n",
    "                if frame_num== sequence_length and stop == False:\n",
    "                    numpy_to_filecsv(np.array(seq_list),file_path)\n",
    "                    seq_list = []\n",
    "\n",
    "                # Nhấn giữ Q để dừng, nhớ xoá video cuối cùng.\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    stop = True\n",
    "                    video_res.release() \n",
    "                    break\n",
    "            last = None\n",
    "            video_res.release()   \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
